Using CPython 3.11.13
Creating virtual environment at: .venv
warning: No `requires-python` value found in the workspace. Defaulting to `>=3.11`.
Resolved 103 packages in 81ms
Installed 101 packages in 4.76s
 + accelerate==1.11.0
 + aiohappyeyeballs==2.6.1
 + aiohttp==3.13.2
 + aiosignal==1.4.0
 + alembic==1.17.1
 + annotated-types==0.7.0
 + antlr4-python3-runtime==4.9.3
 + anyio==4.11.0
 + attrs==25.4.0
 + certifi==2025.10.5
 + charset-normalizer==3.4.4
 + click==8.3.0
 + colorlog==6.10.1
 + contourpy==1.3.3
 + cycler==0.12.1
 + datasets==4.4.1
 + dill==0.4.0
 + evaluate==0.4.6
 + filelock==3.20.0
 + fonttools==4.60.1
 + frozenlist==1.8.0
 + fsspec==2025.10.0
 + fw-lora-experiments==0.1.0 (from file:///home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa)
 + gitdb==4.0.12
 + gitpython==3.1.45
 + greenlet==3.2.4
 + h11==0.16.0
 + hf-xet==1.2.0
 + httpcore==1.0.9
 + httpx==0.28.1
 + huggingface-hub==0.36.0
 + hydra-core==1.3.2
 + idna==3.11
 + jinja2==3.1.6
 + joblib==1.5.2
 + kiwisolver==1.4.9
 + mako==1.3.10
 + markupsafe==3.0.3
 + matplotlib==3.10.7
 + mpmath==1.3.0
 + multidict==6.7.0
 + multiprocess==0.70.18
 + networkx==3.5
 + numpy==2.3.4
 + nvidia-cublas-cu12==12.8.4.1
 + nvidia-cuda-cupti-cu12==12.8.90
 + nvidia-cuda-nvrtc-cu12==12.8.93
 + nvidia-cuda-runtime-cu12==12.8.90
 + nvidia-cudnn-cu12==9.10.2.21
 + nvidia-cufft-cu12==11.3.3.83
 + nvidia-cufile-cu12==1.13.1.3
 + nvidia-curand-cu12==10.3.9.90
 + nvidia-cusolver-cu12==11.7.3.90
 + nvidia-cusparse-cu12==12.5.8.93
 + nvidia-cusparselt-cu12==0.7.1
 + nvidia-nccl-cu12==2.27.5
 + nvidia-nvjitlink-cu12==12.8.93
 + nvidia-nvshmem-cu12==3.3.20
 + nvidia-nvtx-cu12==12.8.90
 + omegaconf==2.3.0
 + optuna==4.5.0
 + packaging==25.0
 + pandas==2.3.3
 + peft==0.17.1
 + pillow==12.0.0
 + platformdirs==4.5.0
 + propcache==0.4.1
 + protobuf==6.33.0
 + psutil==7.1.3
 + pyarrow==22.0.0
 + pydantic==2.12.4
 + pydantic-core==2.41.5
 + pyparsing==3.2.5
 + python-dateutil==2.9.0.post0
 + pytz==2025.2
 + pyyaml==6.0.3
 + regex==2025.11.3
 + requests==2.32.5
 + safetensors==0.6.2
 + scikit-learn==1.7.2
 + scipy==1.16.3
 + seaborn==0.13.2
 + sentry-sdk==2.43.0
 + six==1.17.0
 + smmap==5.0.2
 + sniffio==1.3.1
 + sqlalchemy==2.0.44
 + sympy==1.14.0
 + threadpoolctl==3.6.0
 + tokenizers==0.22.1
 + torch==2.9.0
 + tqdm==4.67.1
 + transformers==4.57.1
 + triton==3.5.0
 + typing-extensions==4.15.0
 + typing-inspection==0.4.2
 + tzdata==2025.2
 + urllib3==2.5.0
 + wandb==0.22.3
 + xxhash==3.6.0
 + yarl==1.22.0
warning: No `requires-python` value found in the workspace. Defaulting to `>=3.11`.
wandb: Currently logged in as: gengaru617 (gengaru617-personal) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run proposed-roberta-base-110M--SST-2-GLUE
wandb: Tracking run with wandb version 0.22.3
wandb: Run data is saved locally in /home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/wandb/run-20251106_181831-proposed-roberta-base-110M--SST-2-GLUE
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run proposed-roberta-base-110M--SST-2-GLUE
wandb: ‚≠êÔ∏è View project at https://wandb.ai/gengaru617-personal/251106-test
wandb: üöÄ View run at https://wandb.ai/gengaru617-personal/251106-test/runs/proposed-roberta-base-110M--SST-2-GLUE
wandb: WARNING The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.
[I 2025-11-06 18:18:32,523] A new study created in memory with name: no-name-13ec0cca-20c8-4d15-8269-62d0dccf8b96
Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]Generating train split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:00<00:00, 897116.28 examples/s]
Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]Generating validation split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 48636.08 examples/s]
Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]Generating test split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1821/1821 [00:00<00:00, 270490.05 examples/s]
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 13503.90 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 14022.84 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 14778.60 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:03, 15174.26 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:03, 15263.42 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:03, 15465.97 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:00<00:03, 15517.67 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 15482.25 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 15600.47 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 15656.71 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:02, 15557.01 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:02, 15628.04 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:04, 9894.38 examples/s] Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 10991.87 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:03, 12057.91 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 12939.90 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 13514.90 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 14094.37 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:02<00:02, 14475.56 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:02<00:01, 14664.19 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:02<00:01, 14989.38 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 15139.74 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 15202.20 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 15299.04 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 15242.41 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 15282.64 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:03<00:00, 15417.88 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:03<00:00, 15499.47 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 9715.41 examples/s] Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 11006.54 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 12081.91 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 12879.55 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 13608.37 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 13348.53 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 11767.50 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:18:59,977] Trial 0 finished with value: 0.515625 and parameters: {'learning_rate': 0.0001110929917661969, 'lambda_fw': 0.00011261446687967564, 'lora_rank': 16, 'warmup_steps': 300, 'batch_size': 32}. Best is trial 0 with value: 0.515625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 14678.87 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 15218.17 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 15183.65 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:03, 15263.85 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:03, 15290.93 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:03, 15242.14 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:00<00:03, 15256.51 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 15334.11 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:05, 9365.20 examples/s] Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:04, 10655.73 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 11771.82 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:03, 12620.64 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:03, 13373.22 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:02, 13936.78 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 14294.83 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 14644.41 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 14881.48 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 14977.70 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:02<00:01, 15179.58 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:02<00:01, 15327.01 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 15234.15 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 15270.08 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 15310.40 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 15228.73 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 15236.29 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 9516.56 examples/s] Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:01, 10676.74 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 11736.72 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 12615.60 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 13237.26 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 13807.28 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 14230.35 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 14437.10 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 13175.24 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 12283.61 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:19:11,827] Trial 1 finished with value: 0.5625 and parameters: {'learning_rate': 0.0001299988216746764, 'lambda_fw': 0.00010110261475659491, 'lora_rank': 16, 'warmup_steps': 300, 'batch_size': 16}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 15134.16 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 15008.82 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 15141.85 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:03, 15100.77 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:03, 14985.30 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:01<00:06, 8845.82 examples/s] Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:05, 10279.32 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:04, 11386.20 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 12346.65 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 13107.62 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 13614.68 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:03, 14029.60 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:02, 14376.84 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:02, 14503.70 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 14708.49 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 14836.45 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 14771.90 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 14827.58 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:02<00:01, 14921.95 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:02<00:01, 14768.13 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 14860.78 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:02, 9515.49 examples/s] Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:02, 10663.93 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 11720.37 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 12554.19 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 13145.74 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:00, 13689.80 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 14138.02 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 14376.50 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 14651.80 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 14899.53 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 14907.65 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 15077.09 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 13079.40 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 11713.16 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:19:23,548] Trial 2 finished with value: 0.4765625 and parameters: {'learning_rate': 0.00018227856835964943, 'lambda_fw': 0.00011057946477901935, 'lora_rank': 4, 'warmup_steps': 600, 'batch_size': 64}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   1%|‚ñè         | 1000/67349 [00:00<00:21, 3116.74 examples/s]Map:   4%|‚ñç         | 3000/67349 [00:00<00:08, 7647.31 examples/s]Map:   7%|‚ñã         | 5000/67349 [00:00<00:06, 10302.94 examples/s]Map:  10%|‚ñà         | 7000/67349 [00:00<00:05, 11905.25 examples/s]Map:  13%|‚ñà‚ñé        | 9000/67349 [00:00<00:04, 13019.64 examples/s]Map:  16%|‚ñà‚ñã        | 11000/67349 [00:00<00:04, 13716.11 examples/s]Map:  19%|‚ñà‚ñâ        | 13000/67349 [00:01<00:03, 14136.50 examples/s]Map:  22%|‚ñà‚ñà‚ñè       | 15000/67349 [00:01<00:03, 14504.61 examples/s]Map:  25%|‚ñà‚ñà‚ñå       | 17000/67349 [00:01<00:03, 14728.40 examples/s]Map:  28%|‚ñà‚ñà‚ñä       | 19000/67349 [00:01<00:03, 14836.15 examples/s]Map:  31%|‚ñà‚ñà‚ñà       | 21000/67349 [00:01<00:03, 15044.11 examples/s]Map:  34%|‚ñà‚ñà‚ñà‚ñç      | 23000/67349 [00:01<00:02, 15119.08 examples/s]Map:  37%|‚ñà‚ñà‚ñà‚ñã      | 25000/67349 [00:01<00:02, 15126.13 examples/s]Map:  40%|‚ñà‚ñà‚ñà‚ñà      | 27000/67349 [00:02<00:02, 15219.52 examples/s]Map:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 29000/67349 [00:02<00:02, 15244.25 examples/s]Map:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 31000/67349 [00:02<00:02, 15105.76 examples/s]Map:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 33000/67349 [00:02<00:02, 15132.21 examples/s]Map:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 35000/67349 [00:02<00:02, 15156.04 examples/s]Map:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 37000/67349 [00:02<00:02, 15103.15 examples/s]Map:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 39000/67349 [00:02<00:01, 15217.20 examples/s]Map:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 41000/67349 [00:02<00:01, 15198.63 examples/s]Map:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 43000/67349 [00:03<00:02, 9550.36 examples/s] Map:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 45000/67349 [00:03<00:02, 10808.07 examples/s]Map:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 47000/67349 [00:03<00:01, 11853.56 examples/s]Map:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 49000/67349 [00:03<00:01, 12628.99 examples/s]Map:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 51000/67349 [00:03<00:01, 13342.45 examples/s]Map:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 53000/67349 [00:03<00:01, 13850.58 examples/s]Map:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 55000/67349 [00:04<00:00, 14160.30 examples/s]Map:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 57000/67349 [00:04<00:00, 14507.83 examples/s]Map:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 59000/67349 [00:04<00:00, 14729.23 examples/s]Map:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 61000/67349 [00:04<00:00, 14819.14 examples/s]Map:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 63000/67349 [00:04<00:00, 15013.95 examples/s]Map:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 65000/67349 [00:04<00:00, 15064.45 examples/s]Map:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 67000/67349 [00:04<00:00, 15123.49 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 13179.97 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 11758.76 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:19:35,646] Trial 3 finished with value: 0.515625 and parameters: {'learning_rate': 0.00017800685374637416, 'lambda_fw': 0.0003114315046468768, 'lora_rank': 8, 'warmup_steps': 700, 'batch_size': 32}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 14618.04 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 14962.49 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 15114.78 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:03, 15149.11 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:06, 8745.24 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:01<00:05, 10267.40 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:04, 11443.13 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:04, 12452.90 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 13240.27 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 13762.73 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 14255.12 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:02, 14595.26 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:02, 14736.20 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:02, 14906.73 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 15073.75 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 15038.09 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 15141.89 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 15174.21 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:02<00:01, 15128.93 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:02<00:01, 15190.69 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 15209.54 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 15152.06 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 15196.13 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 15265.40 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 15202.70 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 9619.67 examples/s] Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:01, 10880.91 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 11860.73 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 12731.30 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 13414.90 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 13894.67 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 14338.50 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 14623.40 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 13157.03 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 11532.84 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:19:47,551] Trial 4 finished with value: 0.515625 and parameters: {'learning_rate': 0.00016733285939034964, 'lambda_fw': 6.51993285350756e-05, 'lora_rank': 16, 'warmup_steps': 400, 'batch_size': 32}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 14636.08 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 14976.41 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 14984.26 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:03, 15156.18 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:03, 15217.38 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:03, 15173.38 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:00<00:03, 15245.81 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 15251.71 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 15302.81 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 15436.05 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:04, 9658.58 examples/s] Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:03, 10882.55 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:03, 11975.82 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 12829.85 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 13491.46 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 14002.29 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 14418.88 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 14648.28 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:02<00:01, 14851.19 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:02<00:01, 15067.84 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:02<00:01, 15126.06 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 15190.62 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 15268.97 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 15225.96 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 15333.70 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:00, 15386.84 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:03<00:00, 15299.53 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:03<00:00, 15337.10 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 15349.62 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 9609.02 examples/s] Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 10851.60 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 11925.04 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 12782.66 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 13312.99 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 12239.22 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:19:59,156] Trial 5 finished with value: 0.4765625 and parameters: {'learning_rate': 0.00020021230416927713, 'lambda_fw': 0.00017544572243488588, 'lora_rank': 8, 'warmup_steps': 600, 'batch_size': 64}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 14762.96 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 14683.82 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 14792.29 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:03, 14955.20 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:03, 14924.92 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:03, 15053.36 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:00<00:03, 15103.75 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 15063.27 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 15176.74 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 15188.60 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 15111.79 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:02, 15180.80 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:04, 9648.87 examples/s] Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 10802.45 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:03, 11870.49 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 12732.47 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 13313.58 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 13879.63 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:02<00:02, 14304.16 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:02<00:01, 14558.33 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 14764.54 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 14879.25 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 14923.52 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 15037.09 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 15115.79 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 15069.53 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:03<00:00, 15143.76 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:03<00:00, 15155.63 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 9518.05 examples/s] Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 10766.85 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 11823.69 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 12604.04 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 13294.40 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 13113.00 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 11612.71 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:20:10,910] Trial 6 finished with value: 0.515625 and parameters: {'learning_rate': 0.00013418455560078896, 'lambda_fw': 0.0001368876196931522, 'lora_rank': 4, 'warmup_steps': 500, 'batch_size': 32}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 15015.40 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 15318.78 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:03, 15377.99 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:03, 15296.79 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:03, 15359.26 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:03, 15444.02 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:00<00:03, 15312.01 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 15379.35 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:05, 9696.08 examples/s] Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:04, 10905.94 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 11983.96 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:03, 12867.77 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:03, 13519.65 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:02, 14057.00 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 14446.42 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 14666.93 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 14917.38 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 15062.19 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:02<00:01, 15119.33 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:02<00:01, 15230.77 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:02<00:01, 15281.30 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 15219.98 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 15222.27 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:02, 9426.79 examples/s] Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 10605.70 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 11687.47 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:01, 12630.24 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 13301.03 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 13902.63 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 14339.15 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 14570.19 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 14831.95 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 15027.49 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 13323.25 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 11956.93 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:20:22,782] Trial 7 finished with value: 0.5625 and parameters: {'learning_rate': 0.00025475358201114856, 'lambda_fw': 6.664793268844866e-05, 'lora_rank': 4, 'warmup_steps': 300, 'batch_size': 16}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 14768.16 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 15187.97 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:07, 7918.23 examples/s] Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:06, 9816.19 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:05, 11287.31 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:01<00:04, 12372.11 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:04, 13240.36 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 13895.35 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 14311.53 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 14698.95 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 14965.96 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:02, 15068.60 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:02, 15234.72 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:02, 15262.46 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 15234.17 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 15336.22 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 15385.44 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:03, 9486.72 examples/s] Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:03<00:02, 10750.72 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:03<00:02, 11847.80 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:02, 12663.80 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 13364.24 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 13944.50 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 14253.41 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 14562.60 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 14819.81 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:00, 14893.26 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 15053.03 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 15166.50 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 15220.64 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 15192.79 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 15237.99 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 15181.19 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 12647.27 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 12261.70 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:20:34,675] Trial 8 finished with value: 0.515625 and parameters: {'learning_rate': 0.00024710521237229267, 'lambda_fw': 9.839746586749036e-05, 'lora_rank': 8, 'warmup_steps': 400, 'batch_size': 32}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 15007.39 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 14865.36 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 15127.99 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:03, 15292.64 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:03, 15198.30 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:03, 15296.48 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:00<00:03, 15344.74 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 15234.80 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 15277.12 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 15341.19 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:02, 15262.60 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:02, 15314.54 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:04, 9619.34 examples/s] Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 10846.04 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:03, 11941.47 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 12810.05 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 13369.87 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 13908.46 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:02<00:02, 14309.20 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:02<00:01, 14547.37 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 14794.95 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 15014.09 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 15067.53 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 15237.86 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 15286.98 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 15233.69 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:01, 9650.37 examples/s] Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:01, 10936.36 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 11957.01 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 12825.40 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 13481.10 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 13905.70 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 14314.30 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 13201.05 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 11830.99 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:20:46,345] Trial 9 finished with value: 0.4765625 and parameters: {'learning_rate': 0.00021995068982558728, 'lambda_fw': 7.751431975342428e-05, 'lora_rank': 8, 'warmup_steps': 300, 'batch_size': 64}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 14476.77 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 14830.34 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 15020.99 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:03, 14988.39 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:03, 15070.50 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:03, 15154.33 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:05, 9230.00 examples/s] Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:04, 10570.48 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:04, 11668.87 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 12530.22 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 13301.90 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:03, 13872.75 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:02, 14190.32 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:02, 14549.16 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 14790.23 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 14815.31 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 14946.84 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 15058.22 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:02<00:01, 15059.72 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:02<00:01, 15124.89 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 15208.89 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:02, 9346.51 examples/s] Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:02, 10610.99 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 11696.01 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 12512.08 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 13237.73 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:00, 13824.19 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 14114.40 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 14424.36 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 14669.39 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 14813.28 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 14915.06 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 15001.23 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 13135.69 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 11248.38 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:20:58,346] Trial 10 finished with value: 0.5625 and parameters: {'learning_rate': 0.0001077077790486191, 'lambda_fw': 0.0002372544725770714, 'lora_rank': 16, 'warmup_steps': 800, 'batch_size': 16}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:12, 5044.04 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:07, 8363.36 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:05, 10509.10 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:04, 12075.03 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:04, 13035.71 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:01<00:04, 13642.61 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:03, 14131.17 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 14500.77 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 14644.71 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 14867.33 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 14995.94 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:02, 15020.36 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:02, 15169.83 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:02, 15275.60 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 15290.92 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 15353.59 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:03, 9643.28 examples/s] Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 10803.10 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:03<00:02, 11894.96 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:03<00:02, 12778.10 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 13411.66 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 13953.06 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 14404.24 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 14609.08 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 14835.75 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 15023.52 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:00, 15058.40 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 15171.63 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 15286.91 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 15205.59 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 15278.73 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 9670.55 examples/s] Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:05<00:00, 10906.46 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 10114.29 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 12617.75 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 12034.67 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:21:10,305] Trial 11 finished with value: 0.5625 and parameters: {'learning_rate': 0.0002988812507320812, 'lambda_fw': 6.0392566979325706e-05, 'lora_rank': 4, 'warmup_steps': 300, 'batch_size': 16}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 14610.43 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 14917.63 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 15179.43 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:03, 15339.53 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:03, 15263.38 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:03, 15348.92 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:00<00:03, 15374.68 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 15315.21 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 15396.03 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 15445.01 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:02, 15433.67 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:02, 15512.17 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:04, 9740.64 examples/s] Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 10918.81 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:03, 12017.90 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 12910.41 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 13476.33 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 13958.24 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:02<00:02, 14364.84 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:02<00:01, 14563.69 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:02<00:01, 14797.41 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 14964.85 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 14979.43 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 15105.28 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 15230.66 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 15216.64 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:03<00:00, 15307.78 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:01, 9684.73 examples/s] Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 10896.68 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 11940.93 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 12815.81 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 13442.91 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 13972.97 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 13321.40 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 12009.74 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:21:21,962] Trial 12 finished with value: 0.5625 and parameters: {'learning_rate': 0.00013924338368277904, 'lambda_fw': 5.320543637895175e-05, 'lora_rank': 16, 'warmup_steps': 400, 'batch_size': 16}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 15038.36 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 15252.13 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:03, 15356.51 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:03, 15306.33 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:03, 15357.51 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:03, 15387.62 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:05, 9087.39 examples/s] Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:04, 10460.85 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:04, 11630.68 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 12531.04 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 13302.43 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:03, 13905.59 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:02, 14270.47 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:02, 14605.11 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 14855.82 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 14957.43 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 15079.33 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 15143.19 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:02<00:01, 15032.83 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:02<00:01, 15104.73 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 15148.72 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 15077.64 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:02, 9546.81 examples/s] Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 10812.06 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 11845.45 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 12763.27 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:00, 13548.66 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 14002.90 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 14380.54 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 14714.82 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 14809.46 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 14975.11 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 15133.41 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 13102.76 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 11734.13 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:21:34,097] Trial 13 finished with value: 0.5625 and parameters: {'learning_rate': 0.00014451347934731778, 'lambda_fw': 8.691183789085222e-05, 'lora_rank': 4, 'warmup_steps': 500, 'batch_size': 16}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 15005.46 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:09, 7028.78 examples/s] Map:   9%|‚ñâ         | 6000/67349 [00:00<00:06, 9325.14 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:05, 11044.55 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:04, 12285.22 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:01<00:04, 13042.11 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:03, 13699.67 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 14211.57 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 14500.59 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 14811.10 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 15006.04 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:02, 15052.86 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:02, 15196.40 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:02, 15314.49 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 15320.03 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 15407.27 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:03, 9467.14 examples/s] Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 10689.04 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:03<00:02, 11808.71 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:03<00:02, 12761.39 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 13448.97 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 14013.36 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 14453.72 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 14680.08 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 14943.73 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 15136.63 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:00, 15182.96 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 15276.63 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 15406.51 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 15366.63 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 15442.25 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 9631.92 examples/s] Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:05<00:00, 10791.99 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 9069.31 examples/s] Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 12464.08 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 11727.39 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:21:46,139] Trial 14 finished with value: 0.5625 and parameters: {'learning_rate': 0.0002845371339165892, 'lambda_fw': 0.00045477987630444626, 'lora_rank': 16, 'warmup_steps': 300, 'batch_size': 16}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 14919.76 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 14875.35 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 15001.73 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:03, 15119.45 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:03, 14983.37 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:03, 15145.64 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:00<00:03, 15242.76 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 15212.83 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 15300.40 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 15375.11 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:02, 15285.38 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:04, 9735.23 examples/s] Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:03, 10961.08 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 11965.23 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 12854.06 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 13530.41 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 13941.58 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 14294.46 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:02<00:02, 14631.41 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:02<00:01, 14797.47 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:02<00:01, 15033.74 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 15179.59 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 15197.46 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 15325.09 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 15345.27 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 15298.61 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:01, 9520.73 examples/s] Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:01, 10751.81 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 11740.50 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 12648.77 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 13371.94 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 13820.79 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 14242.15 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 13159.50 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 12300.76 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:21:57,908] Trial 15 finished with value: 0.5625 and parameters: {'learning_rate': 0.00011997507054592835, 'lambda_fw': 0.0001715200820275232, 'lora_rank': 4, 'warmup_steps': 400, 'batch_size': 16}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 14777.00 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 15134.61 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 15192.45 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:03, 15156.90 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:03, 15166.03 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:01<00:06, 9085.72 examples/s] Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:05, 10399.82 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:04, 11556.99 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 12526.35 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 13149.01 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 13704.55 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:03, 14168.99 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:02, 14441.07 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:02, 14648.19 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 14851.77 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 14839.09 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 14929.17 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 15048.39 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:02<00:01, 14991.27 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:02<00:01, 14994.58 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:02, 9544.59 examples/s] Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:02, 10734.81 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 11759.48 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 12600.37 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 13177.31 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 13735.00 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:00, 14171.57 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 14395.38 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 14688.23 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 14900.40 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 14893.48 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 15036.18 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 15177.60 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 13090.44 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 11848.05 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:22:09,861] Trial 16 finished with value: 0.5625 and parameters: {'learning_rate': 0.000245249315247331, 'lambda_fw': 7.527245822323337e-05, 'lora_rank': 4, 'warmup_steps': 500, 'batch_size': 16}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 14460.55 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 14980.22 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 15007.91 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:03, 15098.25 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:03, 15213.80 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:03, 15169.16 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:00<00:03, 15225.58 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 15253.73 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 15241.00 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 15348.05 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:02, 15446.08 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:02, 15388.43 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:02, 15392.31 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:01<00:02, 15422.57 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:01<00:02, 15353.03 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:03, 9631.90 examples/s] Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:03, 10869.05 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 11879.88 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:02<00:02, 12818.91 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:02<00:02, 13531.62 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 13964.70 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 14382.38 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 14725.83 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 14862.32 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 15008.38 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 15151.62 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:03<00:00, 15137.94 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:03<00:00, 15192.84 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 15259.67 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 15195.35 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 9551.46 examples/s] Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 10806.39 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 11865.57 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 13293.97 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 12232.67 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:22:21,511] Trial 17 finished with value: 0.5625 and parameters: {'learning_rate': 0.00015621474813702, 'lambda_fw': 0.00012909855704294933, 'lora_rank': 16, 'warmup_steps': 300, 'batch_size': 16}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 15061.99 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 14950.07 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 15034.69 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:03, 15178.89 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:03, 15033.59 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:03, 15116.80 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:00<00:03, 15142.27 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 15059.21 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 15119.97 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 15162.15 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:04, 9451.38 examples/s] Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:04, 10728.62 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:03, 11821.56 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 12635.64 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 13366.62 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 13915.49 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 14225.59 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 14546.48 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:02<00:01, 14812.01 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:02<00:01, 14817.63 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 14934.83 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 15019.84 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 15026.67 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 15048.58 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 15077.29 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 14969.74 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:01, 9469.12 examples/s] Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:01, 10667.00 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 11644.07 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 12515.36 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 13250.04 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 13708.73 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 14163.98 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 13092.21 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 11345.45 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:22:33,125] Trial 18 finished with value: 0.5625 and parameters: {'learning_rate': 0.00012524212467113492, 'lambda_fw': 5.347817751191243e-05, 'lora_rank': 4, 'warmup_steps': 400, 'batch_size': 16}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 14696.67 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 15118.66 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 15291.33 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:03, 15210.54 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:03, 15234.37 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:01<00:06, 9031.80 examples/s] Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:05, 10358.96 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:04, 11552.00 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 12534.22 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 13223.88 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 13855.43 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:03, 14350.67 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:02, 14569.51 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:02, 14795.53 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 15000.94 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 14993.48 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 15106.69 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 15234.90 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:02<00:01, 15198.25 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:02<00:01, 15298.15 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:02, 9645.98 examples/s] Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:02, 10877.97 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 11942.61 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 12816.08 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 13390.86 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 13930.40 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:00, 14323.37 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 14548.49 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 14848.75 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 15060.94 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 15113.80 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 15267.23 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 15367.60 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 13275.30 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 12271.74 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:22:44,984] Trial 19 finished with value: 0.5625 and parameters: {'learning_rate': 0.00010058157651610645, 'lambda_fw': 8.86117803031183e-05, 'lora_rank': 16, 'warmup_steps': 800, 'batch_size': 16}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 14777.37 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 15023.08 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 14994.92 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:03, 15068.70 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:03, 15107.23 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:03, 15038.74 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:00<00:03, 15040.05 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 15051.34 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 14959.98 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 14944.95 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 14951.78 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:02, 14864.85 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:02, 14905.33 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:01<00:02, 15008.53 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 14958.59 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:03, 9269.06 examples/s] Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:03, 10480.81 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 11460.98 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:02<00:02, 12337.33 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:02<00:02, 13070.14 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 13546.59 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 13978.32 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 14308.82 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 14422.32 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 14615.68 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 14731.36 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:03<00:00, 14739.16 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 14841.93 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 14941.66 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 14936.27 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 9386.00 examples/s] Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 10598.05 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 11580.24 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 12946.55 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 11740.60 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:22:56,855] Trial 20 finished with value: 0.4765625 and parameters: {'learning_rate': 0.00020519733194363914, 'lambda_fw': 0.000250176433431107, 'lora_rank': 16, 'warmup_steps': 700, 'batch_size': 64}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 14818.85 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 14770.04 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 14928.69 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:03, 15065.30 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:03, 14954.44 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:03, 15072.90 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:00<00:03, 15049.37 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 14900.75 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 14981.63 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 15038.33 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:04, 9142.19 examples/s] Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:04, 10447.31 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:02<00:03, 11552.06 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 12394.29 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 13084.96 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 13680.69 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 13975.55 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 14287.92 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:02<00:02, 14559.86 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:02<00:01, 14692.36 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 14879.46 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 14984.06 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 14982.57 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 15131.79 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 15154.51 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 15121.11 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:01, 9543.69 examples/s] Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:01, 10742.90 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 11708.52 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 12573.85 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 13268.62 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 13739.34 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 14187.11 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 13052.06 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 11758.53 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:23:08,724] Trial 21 finished with value: 0.5625 and parameters: {'learning_rate': 0.00011760296454136795, 'lambda_fw': 0.0002288980431776925, 'lora_rank': 16, 'warmup_steps': 800, 'batch_size': 16}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 14926.91 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 15179.02 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:03, 15343.22 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:03, 15262.12 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:06, 8918.19 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:01<00:05, 10494.72 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:04, 11635.56 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:04, 12622.23 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 13418.06 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 13898.76 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 14304.69 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:02, 14609.85 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:02, 14766.44 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:02, 14948.89 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 15145.04 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 15140.03 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 15234.27 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 15270.84 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:02<00:01, 15209.62 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:03<00:02, 9509.73 examples/s] Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:02, 10765.63 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 11783.48 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 12684.28 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 13419.96 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 13872.09 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 14345.05 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:00, 14688.62 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 14808.16 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 15009.81 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 15194.77 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 15191.33 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 15255.12 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 15328.89 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 13245.39 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 2612.16 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 2559.34 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:23:20,832] Trial 22 finished with value: 0.5625 and parameters: {'learning_rate': 0.0001000047729123769, 'lambda_fw': 0.00035776902747205666, 'lora_rank': 16, 'warmup_steps': 700, 'batch_size': 16}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 14662.27 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 15137.93 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 15275.33 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:03, 15230.66 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:03, 15220.25 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:03, 15327.96 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:00<00:03, 15230.15 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 15335.40 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 15459.38 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 15443.43 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:02, 15550.06 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:02, 15552.47 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:02, 15480.16 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:01<00:02, 15505.93 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:01<00:02, 15547.90 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 15393.72 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 15437.60 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 15435.59 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:02<00:03, 9553.78 examples/s] Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:02<00:02, 10820.44 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:02<00:02, 11865.97 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 12642.35 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 13339.02 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 13883.83 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 14174.56 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 14469.18 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:03<00:00, 14747.87 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:03<00:00, 14813.29 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 15002.98 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 15159.38 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 15129.41 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 15227.24 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 15259.29 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:04<00:00, 13986.12 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 11948.45 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:23:32,640] Trial 23 finished with value: 0.5625 and parameters: {'learning_rate': 0.00010828268479507869, 'lambda_fw': 0.00023266984736689458, 'lora_rank': 16, 'warmup_steps': 600, 'batch_size': 16}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 15074.17 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:09, 7002.83 examples/s] Map:   9%|‚ñâ         | 6000/67349 [00:00<00:06, 9239.42 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:05, 10982.42 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:04, 12176.72 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:01<00:04, 13010.85 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:03, 13694.18 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 14242.77 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 14543.88 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 14838.36 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 15038.09 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:02, 15071.94 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:02, 15205.49 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:02, 15293.28 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 15297.86 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 15388.44 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 15455.46 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:03, 9578.08 examples/s] Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:03<00:02, 10835.56 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:03<00:02, 11927.03 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 12727.43 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 13440.69 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 14000.05 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 14297.07 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 14631.95 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 14876.90 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:00, 15003.06 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 15106.86 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 15227.70 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 15172.86 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 15243.60 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 15264.79 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 15235.54 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 12617.67 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 11645.54 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:23:44,507] Trial 24 finished with value: 0.5625 and parameters: {'learning_rate': 0.00015151741222494818, 'lambda_fw': 0.0001440412270784003, 'lora_rank': 16, 'warmup_steps': 800, 'batch_size': 16}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 14733.79 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 14796.43 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 15012.27 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:03, 15189.97 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:03, 15092.15 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:03, 15177.10 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:00<00:03, 15206.67 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 15110.81 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 15132.63 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 15215.47 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 15030.08 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:02, 15095.49 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:04, 9589.20 examples/s] Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 10823.14 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:03, 11902.94 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 12767.67 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 13356.21 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 13896.16 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:02<00:02, 14290.10 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:02<00:01, 14484.10 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 14737.91 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 14935.97 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 14933.24 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 15006.98 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 15053.42 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 14968.28 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:03<00:00, 15029.90 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:01, 9527.81 examples/s] Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 10718.69 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 11730.08 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 12558.00 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 13221.72 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 13801.77 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 13113.04 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 12053.43 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:23:56,112] Trial 25 finished with value: 0.5625 and parameters: {'learning_rate': 0.00012970613721190386, 'lambda_fw': 0.00018503679227375774, 'lora_rank': 4, 'warmup_steps': 500, 'batch_size': 16}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 14851.62 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 15092.30 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 15188.42 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:03, 15059.12 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:03, 15118.09 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:03, 15189.45 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:05, 9256.60 examples/s] Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:04, 10610.12 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:04, 11798.40 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 12675.87 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 13437.10 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:03, 14017.83 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:02, 14340.93 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:02, 14646.78 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 14898.23 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 14954.42 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 15090.45 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 15196.47 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:02<00:01, 15136.32 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:02<00:01, 15258.33 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:02, 9563.50 examples/s] Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:02, 10759.05 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 11822.34 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 12733.52 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 13287.49 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 13850.38 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:00, 14308.84 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 14531.19 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 14811.13 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 15017.71 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 14994.40 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 15115.90 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 15212.12 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 13193.63 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 11884.97 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:24:07,997] Trial 26 finished with value: 0.5625 and parameters: {'learning_rate': 0.000255720411833291, 'lambda_fw': 0.00028596903789483957, 'lora_rank': 16, 'warmup_steps': 300, 'batch_size': 16}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 14725.05 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 14888.70 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 14914.85 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:03, 15071.15 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:03, 15130.37 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:03, 15082.10 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:00<00:03, 15108.95 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 15141.75 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 15097.32 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 15156.40 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:02, 15209.89 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:02, 15122.44 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:02, 15230.99 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:01<00:02, 15229.74 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:01<00:02, 15178.44 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:03, 9138.90 examples/s] Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:03, 10397.34 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 11414.09 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:02<00:02, 12339.24 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:02<00:02, 13090.82 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 13610.50 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 14085.76 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 14467.91 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 14646.11 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 14814.94 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 14967.99 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:03<00:00, 14945.63 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:03<00:00, 15010.21 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 15127.22 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 15092.37 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 15203.29 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 15273.22 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 9309.27 examples/s] Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 9024.99 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 13001.28 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 11729.12 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:24:19,790] Trial 27 finished with value: 0.5625 and parameters: {'learning_rate': 0.00011365666686738889, 'lambda_fw': 7.099411977327407e-05, 'lora_rank': 16, 'warmup_steps': 400, 'batch_size': 16}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 14487.25 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 14779.33 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 14953.29 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:03, 15051.71 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:03, 14939.72 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:03, 15051.83 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:00<00:03, 15099.79 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 15019.11 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 15090.48 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 15136.28 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 15049.01 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:02, 15116.74 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:02, 15167.76 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:04, 9344.54 examples/s] Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:03, 10592.89 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:03, 11682.47 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 12460.13 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 13145.72 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:02<00:02, 13730.78 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:02<00:01, 14073.71 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 14423.79 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 14708.11 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 14777.16 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 14970.28 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 15113.89 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 15080.28 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:03<00:00, 15171.89 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:03<00:00, 15229.34 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 15122.26 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 9655.33 examples/s] Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 10947.07 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 11928.20 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 12800.91 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 13090.71 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 12103.17 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:24:31,785] Trial 28 finished with value: 0.4765625 and parameters: {'learning_rate': 0.00016206248256773944, 'lambda_fw': 0.00011350886729382901, 'lora_rank': 8, 'warmup_steps': 700, 'batch_size': 64}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 14787.79 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 15163.06 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 15322.89 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:03, 15173.10 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:03, 15227.05 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:03, 15346.03 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:00<00:03, 15318.32 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 15222.10 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 15324.67 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 15266.68 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:02, 15347.10 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:04, 9445.97 examples/s] Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:03, 10649.70 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 11722.52 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 12675.66 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 13319.08 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 13878.74 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 14324.24 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:02<00:02, 14556.48 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:02<00:01, 14810.94 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 15010.35 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 15097.08 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 15204.02 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 15297.75 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 15170.42 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 15276.72 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:03<00:00, 15336.90 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:01, 9429.84 examples/s] Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 10708.76 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 11805.44 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 12661.94 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 13418.33 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 14012.34 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 13221.82 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 11815.32 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-06 18:24:43,448] Trial 29 finished with value: 0.5625 and parameters: {'learning_rate': 0.00010791049369376194, 'lambda_fw': 0.00010196448333351777, 'lora_rank': 4, 'warmup_steps': 300, 'batch_size': 16}. Best is trial 1 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 14889.68 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 15081.80 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 14971.04 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:03, 15134.62 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:03, 15189.72 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:03, 15103.54 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:00<00:03, 15140.23 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:05, 9224.65 examples/s] Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:04, 10504.40 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:04, 11609.28 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 12493.95 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:03, 13105.62 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:03, 13686.13 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:02, 14115.05 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 14387.66 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 14615.60 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 14793.18 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 14840.31 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:02<00:01, 15023.27 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:02<00:01, 15135.48 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 15064.16 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 15145.72 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:02, 9649.81 examples/s] Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 10854.86 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 11868.71 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:03<00:01, 12731.73 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:00, 13357.02 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 13878.17 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 14295.94 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 14464.80 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 14728.08 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:04<00:00, 14881.46 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:04<00:00, 14838.37 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 13160.33 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 11894.83 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/home/toma/pt80-1-a-29/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
wandb: updating run metadata
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading output.log; uploading config.yaml
wandb: uploading history steps 1-2, summary, console lines 578-584
wandb: 
wandb: Run history:
wandb:         epoch ‚ñÅ‚ñÖ‚ñà
wandb:      eval_acc ‚ñÅ‚ñà‚ñÜ
wandb:     eval_loss ‚ñá‚ñà‚ñÅ
wandb: glue_accuracy ‚ñÅ‚ñà‚ñÜ
wandb:      glue_mcc ‚ñÅ‚ñà‚ñÜ
wandb:            lr ‚ñà‚ñÖ‚ñÅ
wandb:     train_acc ‚ñÅ‚ñá‚ñà
wandb:    train_loss ‚ñà‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:    best_eval_acc 0.93922
wandb:            epoch 3
wandb:         eval_acc 0.93807
wandb:        eval_loss 0.18858
wandb:    glue_accuracy 0.93807
wandb:         glue_mcc 0.87612
wandb:               lr 0
wandb: params_trainable 127893508
wandb:      runtime_sec 978.85836
wandb:        train_acc 0.94445
wandb:               +1 ...
wandb: 
wandb: üöÄ View run proposed-roberta-base-110M--SST-2-GLUE at: https://wandb.ai/gengaru617-personal/251106-test/runs/proposed-roberta-base-110M--SST-2-GLUE
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/gengaru617-personal/251106-test
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251106_181831-proposed-roberta-base-110M--SST-2-GLUE/logs
