Using CPython 3.11.14
Creating virtual environment at: .venv
warning: No `requires-python` value found in the workspace. Defaulting to `>=3.11`.
Resolved 103 packages in 111ms
Installed 101 packages in 6.50s
 + accelerate==1.11.0
 + aiohappyeyeballs==2.6.1
 + aiohttp==3.13.2
 + aiosignal==1.4.0
 + alembic==1.17.1
 + annotated-types==0.7.0
 + antlr4-python3-runtime==4.9.3
 + anyio==4.11.0
 + attrs==25.4.0
 + certifi==2025.10.5
 + charset-normalizer==3.4.4
 + click==8.3.0
 + colorlog==6.10.1
 + contourpy==1.3.3
 + cycler==0.12.1
 + datasets==4.4.1
 + dill==0.4.0
 + evaluate==0.4.6
 + filelock==3.20.0
 + fonttools==4.60.1
 + frozenlist==1.8.0
 + fsspec==2025.10.0
 + fw-lora-experiments==0.1.0 (from file:///mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa)
 + gitdb==4.0.12
 + gitpython==3.1.45
 + greenlet==3.2.4
 + h11==0.16.0
 + hf-xet==1.2.0
 + httpcore==1.0.9
 + httpx==0.28.1
 + huggingface-hub==0.36.0
 + hydra-core==1.3.2
 + idna==3.11
 + jinja2==3.1.6
 + joblib==1.5.2
 + kiwisolver==1.4.9
 + mako==1.3.10
 + markupsafe==3.0.3
 + matplotlib==3.10.7
 + mpmath==1.3.0
 + multidict==6.7.0
 + multiprocess==0.70.18
 + networkx==3.5
 + numpy==2.3.4
 + nvidia-cublas-cu12==12.8.4.1
 + nvidia-cuda-cupti-cu12==12.8.90
 + nvidia-cuda-nvrtc-cu12==12.8.93
 + nvidia-cuda-runtime-cu12==12.8.90
 + nvidia-cudnn-cu12==9.10.2.21
 + nvidia-cufft-cu12==11.3.3.83
 + nvidia-cufile-cu12==1.13.1.3
 + nvidia-curand-cu12==10.3.9.90
 + nvidia-cusolver-cu12==11.7.3.90
 + nvidia-cusparse-cu12==12.5.8.93
 + nvidia-cusparselt-cu12==0.7.1
 + nvidia-nccl-cu12==2.27.5
 + nvidia-nvjitlink-cu12==12.8.93
 + nvidia-nvshmem-cu12==3.3.20
 + nvidia-nvtx-cu12==12.8.90
 + omegaconf==2.3.0
 + optuna==4.5.0
 + packaging==25.0
 + pandas==2.3.3
 + peft==0.17.1
 + pillow==12.0.0
 + platformdirs==4.5.0
 + propcache==0.4.1
 + protobuf==6.33.0
 + psutil==7.1.3
 + pyarrow==22.0.0
 + pydantic==2.12.4
 + pydantic-core==2.41.5
 + pyparsing==3.2.5
 + python-dateutil==2.9.0.post0
 + pytz==2025.2
 + pyyaml==6.0.3
 + regex==2025.11.3
 + requests==2.32.5
 + safetensors==0.6.2
 + scikit-learn==1.7.2
 + scipy==1.16.3
 + seaborn==0.13.2
 + sentry-sdk==2.43.0
 + six==1.17.0
 + smmap==5.0.2
 + sniffio==1.3.1
 + sqlalchemy==2.0.44
 + sympy==1.14.0
 + threadpoolctl==3.6.0
 + tokenizers==0.22.1
 + torch==2.9.0
 + tqdm==4.67.1
 + transformers==4.57.1
 + triton==3.5.0
 + typing-extensions==4.15.0
 + typing-inspection==0.4.2
 + tzdata==2025.2
 + urllib3==2.5.0
 + wandb==0.22.3
 + xxhash==3.6.0
 + yarl==1.22.0
warning: No `requires-python` value found in the workspace. Defaulting to `>=3.11`.
wandb: Currently logged in as: gengaru617 (gengaru617-personal) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run comparative-1-roberta-base-110M--SST-2-GLUE
wandb: Tracking run with wandb version 0.22.3
wandb: Run data is saved locally in /mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/wandb/run-20251107_033332-comparative-1-roberta-base-110M--SST-2-GLUE
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run comparative-1-roberta-base-110M--SST-2-GLUE
wandb: ‚≠êÔ∏è View project at https://wandb.ai/gengaru617-personal/251106-test
wandb: üöÄ View run at https://wandb.ai/gengaru617-personal/251106-test/runs/comparative-1-roberta-base-110M--SST-2-GLUE
wandb: WARNING The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.
[I 2025-11-07 03:33:39,025] A new study created in memory with name: no-name-a736f65c-48aa-43b4-b762-d76c64a1e667
Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]Generating train split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:00<00:00, 751636.22 examples/s]
Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]Generating validation split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 126314.39 examples/s]
Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]Generating test split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1821/1821 [00:00<00:00, 230840.74 examples/s]
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:05, 11959.84 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:05, 12412.60 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 13145.01 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:04, 13603.76 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:04, 13306.84 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:04, 13474.75 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:03, 13415.34 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 13628.09 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 13561.18 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 13495.13 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:04, 9935.86 examples/s] Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:03, 10936.86 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:02<00:03, 11610.42 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 12120.69 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:03, 12448.92 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 12550.51 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 12739.86 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 12808.24 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:03<00:02, 12606.34 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:03<00:02, 12658.55 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 12929.78 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 12988.66 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 12899.89 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 13173.58 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 13320.78 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:04<00:01, 13185.86 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:00, 13452.12 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 13452.03 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 9589.82 examples/s] Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 10463.39 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:05<00:00, 11191.54 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:05<00:00, 11718.87 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:05<00:00, 12215.48 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 11405.19 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 12291.23 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 8938.86 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:114: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:177: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-07 03:34:09,805] Trial 0 finished with value: 0.515625 and parameters: {'learning_rate': 6.457050995210032e-05, 'lora_rank': 8, 'batch_size': 32, 'weight_decay': 0.008988888217986286}. Best is trial 0 with value: 0.515625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 13356.29 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 12959.36 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 13430.97 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:04, 13115.37 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:04, 12965.49 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:04, 12964.78 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:04, 12943.71 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 12948.60 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:05, 9460.93 examples/s] Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:04, 10290.96 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:04, 11300.35 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:02<00:03, 11770.78 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:02<00:03, 12124.14 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 12716.58 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 12893.00 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 13022.76 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 12982.67 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 13006.68 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:03<00:02, 13298.94 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:03<00:02, 13013.63 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 13186.47 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 13183.88 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:02, 9995.36 examples/s] Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 10726.73 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:04<00:01, 11366.22 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:04<00:01, 12057.78 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:01, 12503.19 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 12546.00 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 12899.61 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 13040.66 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:05<00:00, 13094.57 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:05<00:00, 13010.49 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:05<00:00, 12962.04 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 11186.42 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 12194.88 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 8606.62 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 8327.58 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:114: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:177: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-07 03:34:21,386] Trial 1 finished with value: 0.4765625 and parameters: {'learning_rate': 3.2724372645156954e-05, 'lora_rank': 4, 'batch_size': 64, 'weight_decay': 0.01659717494682142}. Best is trial 0 with value: 0.515625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 15878.16 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:07, 8669.28 examples/s] Map:   9%|‚ñâ         | 6000/67349 [00:00<00:06, 10039.47 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:05, 11002.75 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:04, 11800.91 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:01<00:04, 12704.43 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:04, 13037.32 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 13083.32 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 13245.99 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 13134.78 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 13152.54 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:03, 13267.57 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:02<00:03, 13273.04 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:02, 13473.73 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 13658.17 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:03, 9643.32 examples/s] Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:03, 10476.79 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:03<00:02, 11183.25 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:03<00:02, 11711.79 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:03<00:02, 12089.15 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:02, 12307.06 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 12532.38 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 12799.23 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 13002.56 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:04<00:01, 13032.66 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:04<00:01, 13105.33 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:01, 13295.64 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 13214.26 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 13300.90 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:05<00:00, 9612.61 examples/s] Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:05<00:00, 10556.42 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:05<00:00, 11331.54 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:05<00:00, 11959.95 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 10586.22 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 11944.75 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 7777.57 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 7373.34 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:114: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:177: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-07 03:34:33,564] Trial 2 finished with value: 0.4765625 and parameters: {'learning_rate': 8.842388630487569e-05, 'lora_rank': 4, 'batch_size': 64, 'weight_decay': 0.017068985168966457}. Best is trial 0 with value: 0.515625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 13135.63 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 13038.10 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 12931.35 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:04, 13249.90 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:04, 13458.27 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:04, 13372.85 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:03, 13353.77 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 12930.96 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 13107.12 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:04, 9722.94 examples/s] Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:04, 10549.65 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:02<00:03, 11134.36 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:02<00:03, 11934.93 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 12262.76 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 12722.07 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 12836.64 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 13136.90 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 13254.84 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:03<00:02, 13509.66 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:03<00:02, 13615.95 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 13475.87 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 13603.42 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 13549.29 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 10382.82 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:04<00:01, 11217.64 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:04<00:01, 11901.94 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:01, 12424.93 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 12700.22 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 12873.96 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 12968.06 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 13077.96 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:05<00:00, 13293.45 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:05<00:00, 13261.39 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 11690.75 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 12452.72 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 8038.90 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 7626.68 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:114: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:177: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-07 03:34:45,049] Trial 3 finished with value: 0.4765625 and parameters: {'learning_rate': 0.00011313441137548273, 'lora_rank': 8, 'batch_size': 64, 'weight_decay': 0.0407916465019101}. Best is trial 0 with value: 0.515625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:05, 12031.90 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 12823.93 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:07, 8334.94 examples/s] Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:06, 9770.64 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:05, 10784.24 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:01<00:04, 11581.20 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:04, 11897.99 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:04, 12374.26 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 12912.78 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 12789.25 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 12743.35 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:02<00:03, 13064.84 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:02<00:03, 12962.31 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 13001.86 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 13197.83 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 13320.98 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 12914.50 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:03<00:03, 9553.32 examples/s] Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:03<00:02, 10417.16 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:03<00:02, 11106.10 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:02, 11805.54 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 12278.40 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 12363.11 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:04<00:01, 12288.74 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:04<00:01, 12758.43 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:04<00:01, 12881.11 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:01, 12981.08 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 12884.21 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 13080.39 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 12694.61 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:05<00:00, 12337.32 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:05<00:00, 9585.62 examples/s] Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:05<00:00, 10508.82 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 10792.34 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 11786.95 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 8769.46 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:114: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:177: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-07 03:34:56,917] Trial 4 finished with value: 0.515625 and parameters: {'learning_rate': 1.5260613546504292e-05, 'lora_rank': 8, 'batch_size': 32, 'weight_decay': 0.04707722350205533}. Best is trial 0 with value: 0.515625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 15185.25 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 13339.19 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 13703.27 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:04, 13464.24 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:04, 13200.69 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:04, 13109.87 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:04, 13175.24 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 13539.51 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 13660.98 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 13451.65 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:04, 9915.66 examples/s] Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:03, 10839.75 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:02<00:03, 11504.94 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 11995.89 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:03, 12214.77 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 12510.22 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 12767.23 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 13038.43 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:03<00:02, 13212.61 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:03<00:02, 13302.32 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 13295.51 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 13258.90 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 13108.85 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 13109.88 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:04<00:01, 9982.21 examples/s] Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:04<00:01, 10704.83 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:01, 11453.09 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 11948.88 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 12411.13 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 12816.81 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 12807.57 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:05<00:00, 13132.03 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:05<00:00, 13446.89 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 12496.64 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 8712.34 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:114: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:177: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-07 03:35:08,971] Trial 5 finished with value: 0.4765625 and parameters: {'learning_rate': 0.00014614054145940125, 'lora_rank': 16, 'batch_size': 64, 'weight_decay': 0.03967326373396701}. Best is trial 0 with value: 0.515625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 13111.17 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 13460.80 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 13349.68 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:06, 9292.87 examples/s] Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:05, 10462.01 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:01<00:04, 11523.53 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:04, 11850.20 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:04, 12198.83 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 13057.39 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 13188.43 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 13173.51 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:03, 13193.69 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:02<00:03, 12784.45 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:02, 13136.27 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 13155.10 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 13195.24 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 13077.18 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:03<00:03, 10184.63 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:03<00:02, 10838.94 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:03<00:02, 11456.72 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:02, 11918.28 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 12102.86 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 12357.33 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 12222.68 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:04<00:01, 12583.86 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:04<00:01, 12456.34 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:01, 12956.38 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 13115.71 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 13204.25 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 13135.31 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:05<00:00, 13261.41 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:05<00:00, 9799.96 examples/s] Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:05<00:00, 10474.24 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 10089.40 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 11923.00 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 8730.48 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:114: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:177: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-07 03:35:20,581] Trial 6 finished with value: 0.4765625 and parameters: {'learning_rate': 2.1278994563876712e-05, 'lora_rank': 8, 'batch_size': 64, 'weight_decay': 0.01291513514730055}. Best is trial 0 with value: 0.515625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 14054.99 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 13534.58 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 13409.80 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:04, 13479.63 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:04, 13271.38 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:04, 13462.75 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:03, 13491.11 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 13377.09 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 13431.41 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 13443.50 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 13421.66 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:04, 10338.97 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:02<00:03, 11318.01 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 11914.38 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 12519.28 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 12664.40 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 12975.83 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 13112.39 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:02<00:02, 13228.46 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:03<00:02, 13276.42 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 13419.41 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 13437.92 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 13424.22 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 13627.99 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 13519.85 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:04<00:01, 9506.56 examples/s] Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:01, 10561.30 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 11450.18 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 12094.76 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 12531.26 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 12868.65 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:05<00:00, 13124.76 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:05<00:00, 13344.04 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 12529.90 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 8315.20 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 7866.55 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:114: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:177: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-07 03:35:32,039] Trial 7 finished with value: 0.5625 and parameters: {'learning_rate': 5.944956054811828e-05, 'lora_rank': 16, 'batch_size': 16, 'weight_decay': 0.03133553965328362}. Best is trial 7 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 13501.09 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 12978.49 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 13224.09 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:04, 13319.40 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:06, 8805.41 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:01<00:05, 9899.77 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:04, 10790.28 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:04, 11696.80 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:04, 12210.85 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 12457.02 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 12822.66 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:02<00:03, 13009.52 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:02<00:03, 12967.91 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 13093.77 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 13218.59 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 13158.49 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 13241.72 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 13261.12 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:03<00:02, 10095.96 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:03<00:02, 10918.39 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:02, 11615.55 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 12086.76 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 12476.48 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 12927.46 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:04<00:01, 12974.14 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:04<00:01, 13047.49 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:01, 13248.80 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 13351.62 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 13557.32 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 13731.63 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 13593.47 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:05<00:00, 13584.65 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:05<00:00, 10548.26 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 10202.41 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 12072.69 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 9281.84 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:114: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:177: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-07 03:35:43,635] Trial 8 finished with value: 0.515625 and parameters: {'learning_rate': 0.00014330961876951687, 'lora_rank': 16, 'batch_size': 32, 'weight_decay': 0.02925545696002545}. Best is trial 7 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 13085.98 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 13087.12 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 13263.28 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:04, 13083.78 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:04, 12931.51 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:04, 12901.41 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:04, 12613.40 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 12885.08 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 12817.90 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 12827.99 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 13080.45 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:03, 13121.37 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:02<00:04, 10134.69 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 10944.71 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:03, 11628.69 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 12030.16 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 12286.03 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 12678.98 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:03<00:02, 12831.02 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:03<00:02, 12949.50 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 13120.99 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 13265.10 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 13606.82 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 13271.10 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 13349.13 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:04<00:01, 13316.78 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:01, 10313.03 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:01, 10887.27 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 11641.56 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 12013.74 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 12410.14 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:05<00:00, 12714.03 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:05<00:00, 12790.78 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 11159.26 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 12297.40 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 8554.00 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 8272.34 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:114: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:177: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-07 03:35:55,237] Trial 9 finished with value: 0.4765625 and parameters: {'learning_rate': 0.00029800782146232496, 'lora_rank': 16, 'batch_size': 64, 'weight_decay': 0.030314301058799}. Best is trial 7 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 15516.10 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 13358.72 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 13097.13 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:04, 13174.16 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:04, 13274.48 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:01<00:05, 9908.06 examples/s] Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:05, 10632.04 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:04, 11319.55 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:04, 11971.34 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 12350.84 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 12603.12 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:03, 12633.72 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:02<00:03, 12832.00 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 12898.70 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 13243.94 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 13131.04 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 13096.19 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 12933.57 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:03<00:02, 13053.20 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:03<00:02, 13068.76 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:02, 9698.95 examples/s] Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:02, 10581.73 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 11180.92 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 11602.20 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:04<00:01, 12053.59 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:04<00:01, 12428.26 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:01, 12994.65 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 13177.18 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 13158.53 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 13197.16 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:05<00:00, 13260.82 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:05<00:00, 13226.46 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:05<00:00, 13194.79 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 11651.54 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 12283.50 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 8655.01 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:114: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:177: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-07 03:36:06,690] Trial 10 finished with value: 0.5625 and parameters: {'learning_rate': 3.8122135880302824e-05, 'lora_rank': 16, 'batch_size': 16, 'weight_decay': 0.0019211407554249813}. Best is trial 7 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:05, 12347.88 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:05, 12550.16 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 13004.80 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:04, 13157.11 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:04, 13075.62 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:04, 12818.15 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:04, 12921.43 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:04, 12721.78 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 12779.30 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 12864.45 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 12918.04 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:03, 12868.59 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:02<00:03, 12874.44 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 12891.38 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 12846.35 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:03, 9917.84 examples/s] Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:03, 10774.71 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 11620.36 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:03<00:02, 12044.56 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:03<00:02, 12190.36 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:02, 12536.20 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 12658.47 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 12726.91 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 12725.70 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:04<00:01, 12871.67 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:04<00:01, 12924.74 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:01, 13250.41 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 13103.37 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 13067.70 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 13109.50 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:05<00:00, 10291.49 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:05<00:00, 10858.45 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:05<00:00, 11595.71 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 11340.75 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 12254.53 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 8561.07 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:114: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:177: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-07 03:36:18,103] Trial 11 finished with value: 0.5625 and parameters: {'learning_rate': 3.7851388105460164e-05, 'lora_rank': 16, 'batch_size': 16, 'weight_decay': 0.023852735094230172}. Best is trial 7 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 15491.20 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 14097.49 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 13617.74 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:04, 13426.65 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:04, 13171.89 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:04, 13334.86 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:04, 13160.67 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 13163.22 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 13249.38 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 13218.35 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:04, 9234.16 examples/s] Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:02<00:04, 10167.14 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:02<00:03, 11017.86 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 11565.67 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:03, 12191.99 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 12402.04 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 12661.99 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 12812.31 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:03<00:02, 12828.93 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:03<00:02, 13029.40 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 13153.77 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 13062.51 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 13168.28 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 13470.28 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 13381.98 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:04<00:01, 9841.00 examples/s] Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:01, 10704.17 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 11434.70 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 12079.25 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 12429.22 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:05<00:00, 12794.08 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:05<00:00, 12935.26 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:05<00:00, 13200.05 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 12101.65 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 12315.51 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 8314.96 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 7875.32 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:114: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:177: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-07 03:36:29,666] Trial 12 finished with value: 0.5625 and parameters: {'learning_rate': 3.9518909199824386e-05, 'lora_rank': 16, 'batch_size': 16, 'weight_decay': 0.005449156292336534}. Best is trial 7 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:05, 12438.31 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 12823.49 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 12993.91 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:04, 13161.99 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:04, 13000.08 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:01<00:05, 9729.31 examples/s] Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:04, 10677.83 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:04, 11525.26 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:04, 12186.99 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 12786.58 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 13098.56 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:03, 13204.06 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:02<00:03, 13060.91 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 13116.09 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 13070.53 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 13081.29 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 12943.27 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 12842.16 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:03<00:02, 13078.16 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:03<00:02, 13496.15 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:02, 9889.81 examples/s] Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:02, 10647.14 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 11347.12 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 12019.39 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:04<00:01, 12209.92 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:04<00:01, 12622.04 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:01, 13010.95 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 13023.11 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 12985.33 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 12881.06 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:05<00:00, 12789.53 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:05<00:00, 12666.13 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:05<00:00, 12722.84 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 11880.70 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 12313.20 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 8714.40 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 8458.84 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:114: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:177: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-07 03:36:41,063] Trial 13 finished with value: 0.5625 and parameters: {'learning_rate': 6.103783414059929e-05, 'lora_rank': 16, 'batch_size': 16, 'weight_decay': 0.0005914860880262295}. Best is trial 7 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 13668.73 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 13245.13 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 13507.57 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:04, 13673.60 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:04, 13508.91 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:04, 13562.11 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:04, 13336.88 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 13612.28 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 13403.62 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 13458.05 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 13478.78 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:03, 13556.78 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:03, 13506.22 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:04, 9794.41 examples/s] Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:03, 10724.55 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:03, 11372.92 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 11856.08 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 12364.73 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:03<00:02, 12588.44 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:03<00:02, 12870.80 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 13045.70 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 13097.54 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 13344.99 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 13417.81 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 13361.65 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:04<00:01, 13343.95 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:00, 13444.80 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 13599.33 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 10683.46 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 11688.49 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 12164.50 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:05<00:00, 12721.11 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:05<00:00, 13038.77 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 11435.95 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 12563.53 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 9329.88 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:114: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:177: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-07 03:36:52,395] Trial 14 finished with value: 0.5625 and parameters: {'learning_rate': 2.267271508260132e-05, 'lora_rank': 16, 'batch_size': 16, 'weight_decay': 0.02375532855470161}. Best is trial 7 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 13171.87 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 12955.29 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 13046.99 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:04, 13325.73 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:04, 13269.21 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:04, 13496.52 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:04, 13215.76 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:05, 9826.46 examples/s] Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:04, 10648.54 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:04, 11306.58 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 11889.96 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:03, 12450.43 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:02<00:03, 12768.19 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 12928.65 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 13038.70 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 13072.15 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 13017.74 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 13050.93 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:03<00:02, 13152.53 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:03<00:02, 13244.89 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 13192.91 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 13268.12 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:02, 10406.73 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 11227.48 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:04<00:01, 11678.41 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:04<00:01, 12133.06 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:01, 12362.79 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 12646.06 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 12832.49 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 12916.45 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 13084.04 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:05<00:00, 13290.27 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:05<00:00, 13294.49 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 12419.18 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 12447.48 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 8563.21 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:114: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:177: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-07 03:37:04,240] Trial 15 finished with value: 0.5625 and parameters: {'learning_rate': 1.0846871171246428e-05, 'lora_rank': 16, 'batch_size': 16, 'weight_decay': 0.03496653928550837}. Best is trial 7 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 14235.42 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 13343.60 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:06, 8897.15 examples/s] Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:05, 10156.89 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:05, 11108.41 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:01<00:04, 11790.01 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:04, 12243.73 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:04, 12475.99 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 12845.25 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 13095.23 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 13050.89 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:03, 13088.56 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:02<00:03, 13140.28 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 13081.35 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 13210.85 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 13312.98 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 13200.81 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:03<00:03, 10272.47 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:03<00:02, 11061.55 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:03<00:02, 11667.52 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:02, 12120.29 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 12512.92 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 12952.76 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 13158.52 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:04<00:01, 13228.52 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:04<00:01, 13173.75 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:01, 13144.23 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 13295.82 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 13339.24 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 13489.23 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:04<00:00, 13572.67 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:05<00:00, 13761.16 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:05<00:00, 10558.96 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 10349.92 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 12204.58 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 8063.59 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 7667.29 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:114: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:177: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-07 03:37:15,822] Trial 16 finished with value: 0.5625 and parameters: {'learning_rate': 5.084311040106224e-05, 'lora_rank': 4, 'batch_size': 16, 'weight_decay': 0.00013616161555266037}. Best is trial 7 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:05, 11666.64 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 12796.50 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 12861.46 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:04, 12865.78 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:04, 12870.32 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:04, 12999.84 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:04, 12928.00 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 13089.64 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 13271.41 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 13113.81 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:04, 9934.19 examples/s] Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:02<00:04, 10779.21 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:02<00:03, 11414.09 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 11966.28 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 12589.16 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 12703.22 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 12793.18 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 12953.65 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:03<00:02, 13022.10 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:03<00:02, 13068.64 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 13077.04 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 12763.79 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 13110.04 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 13416.93 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 13466.00 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:04<00:01, 10451.60 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:01, 11136.28 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 11657.08 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 11947.13 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 12458.54 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:05<00:00, 12521.73 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:05<00:00, 12765.31 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:05<00:00, 12910.61 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 11732.35 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 12323.42 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 8635.53 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:114: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:177: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-07 03:37:27,389] Trial 17 finished with value: 0.5625 and parameters: {'learning_rate': 2.3768107529973468e-05, 'lora_rank': 16, 'batch_size': 16, 'weight_decay': 0.020780967246817862}. Best is trial 7 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 14737.67 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 13889.43 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 13359.87 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:04, 13426.94 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:05, 9641.46 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:01<00:05, 10620.84 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:04, 11273.59 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:04, 11627.56 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:04, 12127.90 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 12463.85 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 12737.02 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:03, 13050.45 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:02<00:03, 13101.01 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 13075.47 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 13001.48 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 13096.66 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 13112.42 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 13012.85 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:03<00:02, 13068.96 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:03<00:02, 9385.60 examples/s] Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:02, 10266.20 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:02, 11046.41 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 11788.67 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 12069.51 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:04<00:01, 12402.66 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:04<00:01, 12665.54 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:01, 12903.53 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 12859.30 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 12968.14 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 13067.59 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:05<00:00, 12872.28 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:05<00:00, 12985.86 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:05<00:00, 13085.59 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 11747.90 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 12211.55 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 8611.07 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 8339.64 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:114: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:177: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-07 03:37:38,778] Trial 18 finished with value: 0.5625 and parameters: {'learning_rate': 0.0002678213968067674, 'lora_rank': 16, 'batch_size': 16, 'weight_decay': 0.03048127045023018}. Best is trial 7 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:05, 12742.37 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 12929.79 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 13009.58 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:04, 12898.39 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:04, 13260.91 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:04, 13465.27 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:04, 13295.13 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 13500.18 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 13725.86 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:03, 13715.55 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:03, 13470.37 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:03, 13275.59 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:01<00:03, 13153.60 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 10045.42 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:03, 10562.99 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:03, 11287.96 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 11715.94 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 12184.33 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:03<00:02, 12536.05 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:03<00:02, 12545.02 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:02, 12588.23 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 12817.72 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 12917.12 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 12764.80 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 13333.12 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:04<00:01, 13261.72 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:00, 13445.91 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:01, 10438.22 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 10930.08 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 11536.38 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:05<00:00, 11940.62 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:05<00:00, 12195.01 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:05<00:00, 12534.94 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 10827.52 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 12253.87 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 8662.76 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 8352.59 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:114: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:177: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
[I 2025-11-07 03:37:50,149] Trial 19 finished with value: 0.5625 and parameters: {'learning_rate': 8.756730261441678e-05, 'lora_rank': 4, 'batch_size': 16, 'weight_decay': 0.049863890985560086}. Best is trial 7 with value: 0.5625.
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|‚ñé         | 2000/67349 [00:00<00:04, 13881.92 examples/s]Map:   6%|‚ñå         | 4000/67349 [00:00<00:04, 13218.14 examples/s]Map:   9%|‚ñâ         | 6000/67349 [00:00<00:04, 13314.89 examples/s]Map:  12%|‚ñà‚ñè        | 8000/67349 [00:00<00:04, 13351.51 examples/s]Map:  15%|‚ñà‚ñç        | 10000/67349 [00:00<00:04, 13138.71 examples/s]Map:  18%|‚ñà‚ñä        | 12000/67349 [00:00<00:04, 13231.94 examples/s]Map:  21%|‚ñà‚ñà        | 14000/67349 [00:01<00:04, 13098.03 examples/s]Map:  24%|‚ñà‚ñà‚ñç       | 16000/67349 [00:01<00:03, 13009.34 examples/s]Map:  27%|‚ñà‚ñà‚ñã       | 18000/67349 [00:01<00:03, 13153.97 examples/s]Map:  30%|‚ñà‚ñà‚ñâ       | 20000/67349 [00:01<00:04, 10154.65 examples/s]Map:  33%|‚ñà‚ñà‚ñà‚ñé      | 22000/67349 [00:01<00:04, 10871.33 examples/s]Map:  36%|‚ñà‚ñà‚ñà‚ñå      | 24000/67349 [00:01<00:03, 11610.98 examples/s]Map:  39%|‚ñà‚ñà‚ñà‚ñä      | 26000/67349 [00:02<00:03, 11861.36 examples/s]Map:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28000/67349 [00:02<00:03, 12524.94 examples/s]Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 30000/67349 [00:02<00:02, 12717.67 examples/s]Map:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 32000/67349 [00:02<00:02, 13025.65 examples/s]Map:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 34000/67349 [00:02<00:02, 12821.06 examples/s]Map:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 36000/67349 [00:02<00:02, 12801.20 examples/s]Map:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 38000/67349 [00:03<00:02, 12888.28 examples/s]Map:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 40000/67349 [00:03<00:02, 12751.34 examples/s]Map:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 42000/67349 [00:03<00:01, 12889.43 examples/s]Map:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 44000/67349 [00:03<00:01, 12864.24 examples/s]Map:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 46000/67349 [00:03<00:01, 13103.64 examples/s]Map:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 48000/67349 [00:03<00:01, 13370.92 examples/s]Map:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 50000/67349 [00:03<00:01, 13153.14 examples/s]Map:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 52000/67349 [00:04<00:01, 13127.43 examples/s]Map:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 54000/67349 [00:04<00:00, 13462.44 examples/s]Map:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 56000/67349 [00:04<00:00, 13167.19 examples/s]Map:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 58000/67349 [00:04<00:00, 10219.37 examples/s]Map:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60000/67349 [00:04<00:00, 10834.00 examples/s]Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 62000/67349 [00:05<00:00, 11409.78 examples/s]Map:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 64000/67349 [00:05<00:00, 11632.90 examples/s]Map:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 66000/67349 [00:05<00:00, 11906.24 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 11138.04 examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67349/67349 [00:05<00:00, 12286.21 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 872/872 [00:00<00:00, 8467.87 examples/s]
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:114: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=str(cfg.training.mixed_precision).lower() in {"fp16", "bf16"})
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:177: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:177: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
/mnt/home/toma/KRK-039/_work/airas-20251106-163904-matsuzawa/airas-20251106-163904-matsuzawa/src/train.py:177: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):
wandb: updating run metadata
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading history steps 1-2, summary, console lines 896-902
wandb: 
wandb: Run history:
wandb:         epoch ‚ñÅ‚ñÖ‚ñà
wandb:      eval_acc ‚ñÅ‚ñà‚ñà
wandb:     eval_loss ‚ñÅ‚ñà‚ñÑ
wandb: glue_accuracy ‚ñÅ‚ñà‚ñà
wandb:      glue_mcc ‚ñÅ‚ñà‚ñà
wandb:            lr ‚ñà‚ñÖ‚ñÅ
wandb:     train_acc ‚ñÅ‚ñá‚ñà
wandb:    train_loss ‚ñà‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:    best_eval_acc 0.93693
wandb:            epoch 3
wandb:         eval_acc 0.93693
wandb:        eval_loss 0.18542
wandb:    glue_accuracy 0.93693
wandb:         glue_mcc 0.87382
wandb:               lr 0
wandb: params_trainable 127893508
wandb:      runtime_sec 586.34077
wandb:        train_acc 0.93654
wandb:               +1 ...
wandb: 
wandb: üöÄ View run comparative-1-roberta-base-110M--SST-2-GLUE at: https://wandb.ai/gengaru617-personal/251106-test/runs/comparative-1-roberta-base-110M--SST-2-GLUE
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/gengaru617-personal/251106-test
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251107_033332-comparative-1-roberta-base-110M--SST-2-GLUE/logs
